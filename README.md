# Start

environment

```
python3 -m venv venv
```

activate

```
source venv/

Install:
```

pip install -r requirements.txt

````

# Pipeline

1. Ingest Data:

```python
python3 ingest_data.py
````

2. create vector index:

```py
python3 create_vector_index.py
```

3. Generate Response to a query(prompt):

```python3
python3 generate_response.py
```

Hereâ€™s a **README.md** draft tailored for your project based on the structure of your app and what youâ€™ve shared ğŸ‘‡

```markdown
# ğŸ“š FastAPI Vector Search App

A FastAPI application that ingests PDF documents, chunks them into embeddings, stores them in MongoDB Atlas, and provides endpoints to query and generate responses using an LLM.

---

## ğŸš€ Features

- FastAPI-based backend with auto-generated Swagger docs.
- Ingests PDF files and chunks them into ~400-character segments.
- Creates a **vector search index** in MongoDB Atlas.
- Generates responses from an LLM (e.g., OpenAI/Hugging Face).
- Configurable via environment variables.

---

## ğŸ“‚ Project Structure
```

.
â”œâ”€â”€ app
â”‚ â”œâ”€â”€ config.py # Configuration and environment variables
â”‚ â”œâ”€â”€ **init**.py
â”‚ â””â”€â”€ main.py # FastAPI entrypoint
â”œâ”€â”€ create_vector_index.py # MongoDB Atlas vector index creation
â”œâ”€â”€ generate_response.py # Call to LLM for generating responses
â”œâ”€â”€ get_embeddings.py # Generate embeddings from text
â”œâ”€â”€ get_query_results.py # Query MongoDB Atlas vector store
â”œâ”€â”€ ingest_data.py # Ingest & chunk PDF documents
â”œâ”€â”€ README.md # Project documentation
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ venv # Virtual environment (not committed)

````

---

## âš™ï¸ Installation

### 1. Clone the repository
```bash
git clone https://github.com/your-username/fastapi-vector-app.git
cd fastapi-vector-app
````

### 2. Create and activate virtual environment

```bash
python -m venv venv
source venv/bin/activate   # On macOS/Linux
venv\Scripts\activate      # On Windows
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ”‘ Configuration

Create a `.env` file in the project root with your settings:

```env
APP_NAME=FastAPI Vector Search
APP_VERSION=0.1.0
DEBUG=True
HOST=127.0.0.1
PORT=8000

DATABASE_URL=mongodb+srv://<user>:<password>@cluster.mongodb.net/db
SECRET_KEY=your-secret-key
API_PREFIX=/api

OPENAI_API_KEY=your-openai-key
```

---

## â–¶ï¸ Running the App

### Option 1: With Uvicorn

```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### Option 2: Directly with Python

```bash
python app/main.py
```

---

## ğŸ“¡ API Endpoints

| Method | Endpoint        | Description                              |
| ------ | --------------- | ---------------------------------------- |
| GET    | `/`             | Root health check                        |
| GET    | `/info`         | Show app info from environment variables |
| GET    | `/env-test`     | Verify environment variables             |
| GET    | `/ingest-data`  | Ingest and chunk PDF into embeddings     |
| GET    | `/create-index` | Create MongoDB Atlas vector index        |
| GET    | `/prompt`       | Generate a response using the LLM        |

Docs are auto-generated:

- Swagger UI â†’ [http://localhost:8000/docs](http://localhost:8000/docs)
- ReDoc â†’ [http://localhost:8000/redoc](http://localhost:8000/redoc)

---

## ğŸ› ï¸ Development Notes

- Runs on **FastAPI + Uvicorn**.
- Requires **MongoDB Atlas** with vector index support.
- Supports **OpenAI/HuggingFace LLMs** for generating responses.
- Extendable for custom embeddings & retrieval-augmented generation.

---

## ğŸ“œ License

MIT License. Feel free to use and modify.

---

## ğŸ‘¨â€ğŸ’» Author

Developed by **\[Robiul Hossain]**
